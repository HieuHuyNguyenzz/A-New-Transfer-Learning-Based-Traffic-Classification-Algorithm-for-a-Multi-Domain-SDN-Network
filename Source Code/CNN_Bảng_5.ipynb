{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1NVS2leyBvWR6q6PSq6u7Oq95UfSIj3_p","timestamp":1717913342571}],"authorship_tag":"ABX9TyOBA7+D6nDwciAaaiM4FzYW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"x280WQxR501t","executionInfo":{"status":"ok","timestamp":1717932127667,"user_tz":-420,"elapsed":7070,"user":{"displayName":"Duy Quang","userId":"08397240359579863284"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import datetime\n","import copy\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.layers import TimeDistributed, Conv1D, MaxPool1D, Flatten, LSTM, Dense, AveragePooling1D, Dropout, Conv2D, MaxPool2D\n","from keras.models import Sequential\n","from keras.regularizers import l2\n","import sklearn.metrics as metrics\n","from pyarrow import feather"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8aon6xdx6H1u","executionInfo":{"status":"ok","timestamp":1717932150106,"user_tz":-420,"elapsed":22444,"user":{"displayName":"Duy Quang","userId":"08397240359579863284"}},"outputId":"a70f3e6d-63ca-4165-cd0c-745185427060"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["NUM_EPOCHS = 100\n","BATCH_SIZE = 32\n","client_lr = 3e-4\n","NUM_PACKET = 5"],"metadata":{"id":"NbujurkYWNDC","executionInfo":{"status":"ok","timestamp":1717932150107,"user_tz":-420,"elapsed":19,"user":{"displayName":"Duy Quang","userId":"08397240359579863284"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def data_processing(df, NUM_FEATURES):\n","   y_train = df['Label']\n","   flow_id = df['flow_id']\n","\n","   df = df/255\n","\n","   X_train = df.drop(['Label', 'flow_id'], axis=1)\n","   X_train = X_train.to_numpy()\n","\n","   X_train = X_train.reshape(-1, NUM_PACKET, NUM_FEATURES, 1)\n","   y_train = y_train.to_numpy()\n","\n","   y_train = y_train.reshape(-1,NUM_PACKET)[:,-1]\n","   return X_train, y_train\n","def DoiNhan(label: np.array):\n","  for i in range(len(label)):\n","    if label[i] == 14 or label[i] == 16 or label[i] == 13:\n","      label[i] = 2\n","    elif label[i] == 11 or label[i] == 5 or label[i] == 10:\n","      label[i] = 1\n","    elif label[i] == 4 or label[i] == 8 or label[i] == 9 or label[i] == 1 or label[i] == 7:\n","      label[i] = 0"],"metadata":{"id":"f0I9b1B46XFf","executionInfo":{"status":"ok","timestamp":1717932150107,"user_tz":-420,"elapsed":14,"user":{"displayName":"Duy Quang","userId":"08397240359579863284"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from keras import backend as K\n","\n","def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))"],"metadata":{"id":"jZ82om57kAJX","executionInfo":{"status":"ok","timestamp":1717932150107,"user_tz":-420,"elapsed":13,"user":{"displayName":"Duy Quang","userId":"08397240359579863284"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def train_CNN(X, y, X_test, y_test):\n","    model = Sequential()\n","    model.add(Conv2D(filters=128, kernel_size=(5, 5), padding='Same',\n","                     activation='relu', input_shape=(NUM_PACKET,128,1)))\n","    model.add(Conv2D(filters=64 , kernel_size=(5, 5), padding='Same',\n","                     activation='relu'))\n","    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='Same'))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same',\n","                     activation='relu'))\n","    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same',\n","                     activation='relu'))\n","    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='Same'))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same',\n","                     activation='relu'))\n","    model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same',\n","                     activation='relu'))\n","    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='Same'))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='Same',\n","                     activation='relu'))\n","    model.add(Conv2D(filters=8, kernel_size=(3, 3), padding='Same',\n","                     activation='relu'))\n","    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='Same'))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Flatten())\n","    model.add(Dense(256, activation=\"relu\"))\n","    model.add(Dropout(0.1))\n","    model.add(Dense(3, activation=\"softmax\"))\n","\n","    model.compile(optimizer=tf.keras.optimizers.Adam(\n","    learning_rate=client_lr), loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n","\n","    model.fit(X, y, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, shuffle=True)\n","    predictions = model.predict(X_test, verbose=2, batch_size=BATCH_SIZE)\n","    y_pred = np.argmax(predictions, axis=-1)\n","\n","    print(metrics.classification_report(y_test, y_pred))\n","\n","    return model"],"metadata":{"id":"zsZGfcZa6dJi","executionInfo":{"status":"ok","timestamp":1717932243202,"user_tz":-420,"elapsed":329,"user":{"displayName":"Duy Quang","userId":"08397240359579863284"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","def Training_Step():\n","  path = '/content/drive/MyDrive/Fixed_data/'\n","  test_name = 'd1test'\n","  train_name ='d1train'\n","  BATCH_SIZE = 32\n","\n","  res = []\n","  train_data = feather.read_feather(path + train_name + str(1))\n","  test_data = feather.read_feather(path + test_name + str(1))\n","\n","  X_train, y_train = data_processing(train_data, 128)\n","  X_test, y_test = data_processing(test_data, 128)\n","\n","  DoiNhan(y_train)\n","  DoiNhan(y_test)\n","\n","  CNN_model = train_CNN(X_train, y_train, X_test, y_test)\n","  flows = set(test_data['flow_id'])\n","  print(flows)\n","  l = []\n","  for id in flows:\n","    df = test_data.loc[test_data['flow_id'] == id]\n","    X_check, y_check = data_processing(df, 128)\n","    DoiNhan(y_check)\n","\n","    start = time.time()\n","    y_pred = CNN_model.predict(X_check, verbose=0, batch_size=BATCH_SIZE)\n","    end = time.time()\n","\n","    length = end - start\n","    l.append(length)\n","  res = sum(l) / len(flows)\n","  return res"],"metadata":{"id":"xiYoMjqR7NLt","executionInfo":{"status":"ok","timestamp":1717932244167,"user_tz":-420,"elapsed":3,"user":{"displayName":"Duy Quang","userId":"08397240359579863284"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["afct = Training_Step()\n","print(afct)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rYVG1QJ5UhKa","outputId":"34214e18-8a2c-4e83-e210-921ee2f0b8be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","11/11 [==============================] - 9s 624ms/step - loss: 1.0951 - sparse_categorical_accuracy: 0.5284\n","Epoch 2/100\n"," 4/11 [=========>....................] - ETA: 7s - loss: 1.0833 - sparse_categorical_accuracy: 0.5469"]}]},{"cell_type":"code","source":["print(afct)"],"metadata":{"id":"OdekSqa_-52F","executionInfo":{"status":"aborted","timestamp":1717932155603,"user_tz":-420,"elapsed":7,"user":{"displayName":"Duy Quang","userId":"08397240359579863284"}}},"execution_count":null,"outputs":[]}]}